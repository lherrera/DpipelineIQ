{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "26b029cc-6017-418f-b2b9-dcef3e722bf3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# PipelineIQ Incremental Processing\n",
    "\n",
    "This notebook processes new and updated use cases incrementally using watermark-based loading.\n",
    "\n",
    "**Pipeline Flow:**\n",
    "1. Load only new/changed records from source (based on `piq_last_updated` watermark)\n",
    "2. Apply AI enrichments sequentially\n",
    "3. MERGE results into target table\n",
    "\n",
    "**Design: Minimized Column Storage**\n",
    "- The `pipelineiq` table stores only essential columns:\n",
    "  - `usecase_id` (primary key)\n",
    "  - `last_modified_date` (from source, to detect updates)\n",
    "  - `piq_last_updated` (watermark, set to CURRENT_DATE() when processed)\n",
    "  - `competition_string` (needed for AI inference)\n",
    "  - All AI-generated fields (context, confidence scores, recommendations, etc.)\n",
    "- For reporting, join back to `main.gtm_data.core_usecase_curated` on `usecase_id` to get source fields like `usecase_name`, `account_name`, `stage`, etc.\n",
    "- This minimizes storage and focuses the pipeline on AI enrichment only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05d26789-888a-408f-979d-de47632907d7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Configs"
    }
   },
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    # Filter Criteria\n",
    "    \"min_monthly_dbus\": 1000,\n",
    "    \"excluded_stages\": ['U1', 'Lost', 'Closed', 'Disqualified'],\n",
    "    \"target_live_date_months_ahead\": 6,\n",
    "    \"last_modified_months_back\": -6,\n",
    "    \n",
    "    # AI Model Settings\n",
    "    \"ai_model\": \"databricks-gpt-oss-20b\",\n",
    "    \"temperature\": 0.0,\n",
    "    \"top_p\": 0.1,\n",
    "    \n",
    "    # Token Limits\n",
    "    \"max_tokens_summarize\": 100,\n",
    "    \"max_tokens_oneliner\": 50,\n",
    "    \"max_tokens_confidence\": 200,\n",
    "    \"max_tokens_classification\": 20,\n",
    "    \"max_tokens_recommendation\": 200,\n",
    "    \n",
    "    # Confidence Thresholds\n",
    "    \"confidence_high_threshold\": 75,\n",
    "    \"confidence_medium_threshold\": 45,\n",
    "    \n",
    "    # MEDDPICC Weights\n",
    "    \"meddpicc_weights\": {\n",
    "        \"pain\": 0.25,\n",
    "        \"champion\": 0.20,\n",
    "        \"implementation_plan\": 0.20,\n",
    "        \"decision_process\": 0.10,\n",
    "        \"urgency\": 0.10,\n",
    "        \"competition_awareness\": 0.05,\n",
    "        \"measurable_impact\": 0.02,\n",
    "        \"major_blockers\": -0.08\n",
    "    }\n",
    "}\n",
    "\n",
    "# Use Case Type Categories\n",
    "USECASE_TYPE_CATEGORIES = [\n",
    "    'Machine Learning', 'Generative AI', 'Data Warehousing', \n",
    "    'Migration AI', 'Migration Unity Catalog', 'Migration DWH', \n",
    "    'Migration ETL', 'Migration Streaming', 'Migration BI',\n",
    "    'BI', 'ETL', 'Governance', 'Streaming', 'Ingestion', 'Platform', 'Other'\n",
    "]\n",
    "\n",
    "# =============================================================================\n",
    "# WIDGETS FOR PARAMETERIZATION\n",
    "# =============================================================================\n",
    "\n",
    "# Create widgets for catalog and schema\n",
    "dbutils.widgets.text(\"catalog\", \"users\", \"Target Catalog\")\n",
    "dbutils.widgets.text(\"schema\", \"sam_lecorre\", \"Target Schema\")\n",
    "\n",
    "# Get widget values\n",
    "TARGET_CATALOG = dbutils.widgets.get(\"catalog\")\n",
    "TARGET_SCHEMA = dbutils.widgets.get(\"schema\")\n",
    "TARGET_TABLE = f\"{TARGET_CATALOG}.{TARGET_SCHEMA}.pipelineiq\"\n",
    "SOURCE_TABLE = \"main.gtm_data.core_usecase_curated\"\n",
    "\n",
    "print(f\"Target Catalog: {TARGET_CATALOG}\")\n",
    "print(f\"Target Schema: {TARGET_SCHEMA}\")\n",
    "print(f\"Target Table: {TARGET_TABLE}\")\n",
    "print(f\"Source Table: {SOURCE_TABLE}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SETUP & VALIDATION\n",
    "# =============================================================================\n",
    "\n",
    "# Set Spark configurations for performance\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"64\")\n",
    "spark.conf.set(\"spark.databricks.execution.timeout\", \"14400\")\n",
    "\n",
    "# Check if target table exists\n",
    "table_exists = spark.catalog.tableExists(TARGET_TABLE)\n",
    "\n",
    "if not table_exists:\n",
    "    print(f\"âš ï¸  Target table {TARGET_TABLE} does not exist. Creating empty table...\")\n",
    "    \n",
    "    # Create empty target table with schema from source\n",
    "    # We'll add the AI enrichment columns in the first merge\n",
    "    spark.sql(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {TARGET_TABLE}\n",
    "        (\n",
    "        -- Core identifiers and timestamps\n",
    "        usecase_id STRING COMMENT 'Primary key - use case identifier from source system',\n",
    "        last_modified_date DATE COMMENT 'Last modified date from source system (used to detect updates)',\n",
    "        piq_last_updated DATE COMMENT 'Watermark column - date when this record was last processed by PipelineIQ',\n",
    "        \n",
    "        -- Fields needed for AI inference\n",
    "        competition_string STRING COMMENT 'Competition information from source (used for AI inference)',\n",
    "        num_of_blockers BIGINT COMMENT 'Number of blockers from source',\n",
    "        \n",
    "        -- AI enriched fields\n",
    "        context STRING COMMENT 'AI-generated summary of BDR context and business impact for the use case',\n",
    "        one_liner STRING COMMENT 'AI-generated concise summary of the use case',\n",
    "        next_steps_summary STRING COMMENT 'AI-generated summary of next steps for the use case',\n",
    "        implementation_notes_summary STRING COMMENT 'AI-generated summary of implementation notes',\n",
    "        blockers_summary STRING COMMENT 'AI-generated summary of blockers',\n",
    "        usecase_type STRING COMMENT 'AI-classified technical use case category',\n",
    "        business_usecase_type STRING COMMENT 'AI-generated business use case label (max 5 words)',\n",
    "        soundbyte STRING COMMENT 'AI-generated executive elevator pitch connecting technical solution to business outcome',\n",
    "        \n",
    "        -- Confidence scoring\n",
    "        ai_confidence_score_advanced STRING COMMENT 'Raw AI-generated MEDDPICC confidence assessment output',\n",
    "        confidence_score INT COMMENT 'AI-extracted confidence score (0-100) for successful go-live',\n",
    "        confidence_level STRING COMMENT 'AI-extracted confidence level (High, Medium, Low)',\n",
    "        rationale_for_confidence_score STRING COMMENT 'AI-extracted rationale for confidence score',\n",
    "        pain_score INT COMMENT 'AI-extracted MEDDPICC Pain dimension score (0-10)',\n",
    "        champion_score INT COMMENT 'AI-extracted MEDDPICC Champion dimension score (0-10)',\n",
    "        implementationplan_score INT COMMENT 'AI-extracted MEDDPICC Implementation Plan dimension score (0-10)',\n",
    "        decisionprocess_score INT COMMENT 'AI-extracted MEDDPICC Decision Process dimension score (0-10)',\n",
    "        urgency_score INT COMMENT 'AI-extracted MEDDPICC Urgency dimension score (0-10)',\n",
    "        competitionawareness_score INT COMMENT 'AI-extracted MEDDPICC Competition Awareness dimension score (0-10)',\n",
    "        majorblockers_score INT COMMENT 'AI-extracted MEDDPICC Major Blockers dimension score (0-10)',\n",
    "        measurableimpact_score INT COMMENT 'AI-extracted MEDDPICC Measurable Impact dimension score (0-10)',\n",
    "        confidence_level_normalized STRING COMMENT 'Normalized confidence level (High, Medium, Low, Not computed)',\n",
    "        \n",
    "        -- Recommendations and classifications\n",
    "        next_best_action_recommendation STRING COMMENT 'AI-generated next best action recommendation for account team',\n",
    "        likely_to_slip BOOLEAN COMMENT 'Flag if use case is likely to slip (true/false)',\n",
    "        slippage_category STRING COMMENT 'AI-classified primary reason for slippage',\n",
    "        can_be_accelerated BOOLEAN COMMENT 'Flag if use case can be accelerated (true/false)',\n",
    "        accel_category STRING COMMENT 'AI-classified best acceleration lever'\n",
    "        )\n",
    "        USING DELTA\n",
    "        COMMENT 'PipelineIQ AI-enriched use case insights with minimized storage footprint'\n",
    "        TBLPROPERTIES (\n",
    "        'delta.enableChangeDataFeed' = 'true'\n",
    "        )\n",
    "    \"\"\")\n",
    "    \n",
    "    print(f\"âœ… Created empty table {TARGET_TABLE}\")\n",
    "    watermark_date = \"1900-01-01\"\n",
    "else:\n",
    "    print(f\"âœ… Target table {TARGET_TABLE} exists\")\n",
    "    \n",
    "    # Query watermark - use piq_last_updated as the watermark column\n",
    "    watermark_result = spark.sql(f\"\"\"\n",
    "        SELECT COALESCE(MAX(piq_last_updated), '1900-01-01') AS max_date\n",
    "        FROM {TARGET_TABLE}\n",
    "    \"\"\").first()\n",
    "    \n",
    "    watermark_date = str(watermark_result['max_date'])\n",
    "    print(f\"ðŸ“… Watermark date (piq_last_updated): {watermark_date}\")\n",
    "\n",
    "# Store watermark as temp variable for SQL\n",
    "spark.sql(f\"\"\"DECLARE OR REPLACE VARIABLE watermark_date STRING DEFAULT '{watermark_date}'\"\"\")\n",
    "\n",
    "# Store config values as SQL variables\n",
    "spark.sql(f\"\"\"DECLARE OR REPLACE VARIABLE min_dbus INT DEFAULT {CONFIG['min_monthly_dbus']}\"\"\")\n",
    "spark.sql(f\"\"\"DECLARE OR REPLACE VARIABLE target_months INT DEFAULT {CONFIG['target_live_date_months_ahead']}\"\"\")\n",
    "spark.sql(f\"\"\"DECLARE OR REPLACE VARIABLE last_modified_months INT DEFAULT {CONFIG['last_modified_months_back']}\"\"\")\n",
    "\n",
    "print(f\"\\nâœ… Setup complete. Ready to process incremental data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "926f7605-37a7-4c78-a5b4-1688ef818c50",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Get latest usecases"
    },
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Load and filter new/updated use cases based on watermark\n",
    "-- Only load records where source last_modified_date > our piq_last_updated watermark\n",
    "CREATE OR REPLACE TEMPORARY VIEW filtered_usecases AS\n",
    "SELECT \n",
    "  usecase_id,\n",
    "  last_modified_date,\n",
    "  \n",
    "  -- Fields needed for AI inference\n",
    "  sdr_bdr_notes,\n",
    "  business_impact,\n",
    "  business_outcome_description,\n",
    "  ae_authority,\n",
    "  ae_money_budget,\n",
    "  usecase_name,\n",
    "  usecase_description,\n",
    "  demand_plan_stage_next_steps,\n",
    "  implementation_notes,\n",
    "  COALESCE(num_of_blockers, 0) AS num_of_blockers,\n",
    "  last_modified_blocker_category,\n",
    "  last_modified_blocker_comment,\n",
    "  competition_string,\n",
    "  industry_imperative\n",
    "  \n",
    "FROM main.gtm_data.core_usecase_curated\n",
    "WHERE \n",
    "  last_modified_date > watermark_date\n",
    "  AND estimated_monthly_dollar_dbus >= min_dbus\n",
    "  AND stage NOT IN ('U1', 'Lost', 'Closed', 'Disqualified')\n",
    "  AND target_live_date BETWEEN CURRENT_DATE() AND ADD_MONTHS(CURRENT_DATE(), target_months)\n",
    "  AND last_modified_date >= ADD_MONTHS(CURRENT_DATE(), last_modified_months)\n",
    "ORDER BY estimated_monthly_dollar_dbus DESC;\n",
    "\n",
    "-- Display count and sample\n",
    "SELECT \n",
    "  COUNT(*) AS new_usecases_count,\n",
    "  MIN(last_modified_date) AS oldest_modified,\n",
    "  MAX(last_modified_date) AS newest_modified\n",
    "FROM filtered_usecases;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d4a4f3a-1c32-42db-a206-13be4923c33e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Summarise use case context"
    },
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Generate contextual summaries using AI\n",
    "CREATE OR REPLACE TEMPORARY VIEW ai_context AS\n",
    "SELECT \n",
    "  usecase_id,\n",
    "  CASE \n",
    "    WHEN (sdr_bdr_notes IS NOT NULL AND LENGTH(TRIM(sdr_bdr_notes)) > 0)\n",
    "      OR (business_impact IS NOT NULL AND LENGTH(TRIM(business_impact)) > 0)\n",
    "      OR (business_outcome_description IS NOT NULL AND LENGTH(TRIM(business_outcome_description)) > 0)\n",
    "      OR (ae_authority IS NOT NULL AND LENGTH(TRIM(ae_authority)) > 0)\n",
    "      OR (ae_money_budget IS NOT NULL AND LENGTH(TRIM(ae_money_budget)) > 0)\n",
    "    THEN\n",
    "      ai_summarize(\n",
    "        CONCAT(\n",
    "          'Summarize the following context and business impact into a concise paragraph (max 4 sentences). Focus on the main challenge, expected business value, the main type of contact (e.g., Executive sponsor, technical decision maker, Economic decision maker, etc), and whether funding is available or approved. Context: ',\n",
    "          COALESCE(TRIM(LEFT(regexp_replace(sdr_bdr_notes, '<[^>]+>', ''), 2000)), 'No context provided. '),\n",
    "          'Business Impact: ', COALESCE(TRIM(business_impact), 'No business impact provided. '),\n",
    "          'Business Outcome: ', COALESCE(TRIM(business_outcome_description), 'No business outcome provided. '),\n",
    "          'Main Contact Type: ', COALESCE(TRIM(ae_authority), 'Not specified.'),\n",
    "          'Funding Status: ', COALESCE(TRIM(ae_money_budget), 'Not specified.')\n",
    "        ),\n",
    "        100\n",
    "      )\n",
    "    ELSE\n",
    "      'No context or business impact provided.'\n",
    "  END AS context\n",
    "FROM filtered_usecases;\n",
    "\n",
    "-- Preview\n",
    "-- SELECT * FROM ai_context LIMIT 5;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32dd539a-fead-4e9b-971a-f99af50970b0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Add oneliners"
    },
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Generate one-liner summaries using AI\n",
    "CREATE OR REPLACE TEMPORARY VIEW ai_oneliner AS\n",
    "SELECT \n",
    "  f.usecase_id,\n",
    "  CASE\n",
    "    WHEN (f.usecase_name IS NOT NULL AND LENGTH(TRIM(f.usecase_name)) > 0)\n",
    "      OR (f.usecase_description IS NOT NULL AND LENGTH(TRIM(f.usecase_description)) > 0)\n",
    "    THEN\n",
    "      ai_summarize(\n",
    "        CONCAT(\n",
    "          'Generate a short, clear one-line summary (max 50 words) describing the core business objective of this use case. ',\n",
    "          'Account Context: ', COALESCE(TRIM(c.context), 'No account context'),\n",
    "          ' Use Case Name: ', COALESCE(TRIM(f.usecase_name), 'Use Case name not provided.'),\n",
    "          '. Description: ', COALESCE(TRIM(f.usecase_description), 'No description provided.')\n",
    "        ),\n",
    "        50\n",
    "      )\n",
    "    ELSE\n",
    "      'No use case name or description provided'\n",
    "  END AS one_liner\n",
    "FROM filtered_usecases f\n",
    "LEFT JOIN ai_context c ON f.usecase_id = c.usecase_id;\n",
    "\n",
    "-- SELECT * FROM ai_oneliner LIMIT 5;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aeb8be43-fc1a-43f4-8273-ebe3f3c9830a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Add next steps"
    },
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Generate next steps summaries using AI\n",
    "CREATE OR REPLACE TEMPORARY VIEW ai_nextsteps AS\n",
    "SELECT \n",
    "  usecase_id,\n",
    "  CASE \n",
    "    WHEN demand_plan_stage_next_steps IS NOT NULL \n",
    "         AND LENGTH(TRIM(demand_plan_stage_next_steps)) > 0 THEN\n",
    "      ai_summarize(\n",
    "        CONCAT(\n",
    "          'Summarize the following next steps into a short, action-oriented sentence focusing on immediate priorities: ',\n",
    "          TRIM(demand_plan_stage_next_steps)\n",
    "        ),\n",
    "        100\n",
    "      )\n",
    "    ELSE\n",
    "      'No next steps provided'\n",
    "  END AS next_steps_summary\n",
    "FROM filtered_usecases;\n",
    "\n",
    "-- SELECT * FROM ai_nextsteps LIMIT 5;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abfa9b0d-15ae-4e6a-8fc0-334c7506edf5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Summarise implementation notes"
    },
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Generate implementation notes summaries using AI\n",
    "CREATE OR REPLACE TEMPORARY VIEW ai_implementation AS\n",
    "SELECT \n",
    "  usecase_id,\n",
    "  CASE \n",
    "    WHEN implementation_notes IS NOT NULL AND LENGTH(TRIM(implementation_notes)) > 0 THEN\n",
    "      ai_summarize(\n",
    "        CONCAT(\n",
    "          'Summarize the following implementation notes into a short, action-oriented paragraph focusing on key steps, milestones, and ownership: ',\n",
    "          implementation_notes\n",
    "        ),\n",
    "        100\n",
    "      )\n",
    "    ELSE\n",
    "      'There is no implementation plan or not specified in Salesforce'\n",
    "  END AS implementation_notes_summary\n",
    "FROM filtered_usecases;\n",
    "\n",
    "-- SELECT * FROM ai_implementation LIMIT 5;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c93ea9b9-87a5-46a9-b58c-214bb75973db",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Add blockers"
    },
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Generate blockers summaries using AI\n",
    "CREATE OR REPLACE TEMPORARY VIEW ai_blockers AS\n",
    "SELECT \n",
    "  usecase_id,\n",
    "  CASE \n",
    "    WHEN num_of_blockers = 0 THEN 'There are 0 blockers'\n",
    "    WHEN (last_modified_blocker_category IS NULL OR LENGTH(TRIM(last_modified_blocker_category)) = 0)\n",
    "      AND (last_modified_blocker_comment IS NULL OR LENGTH(TRIM(last_modified_blocker_comment)) = 0)\n",
    "      THEN 'Blocker details not provided'\n",
    "    ELSE CONCAT(\n",
    "      'There are ', CAST(num_of_blockers AS STRING), ' blockers. ',\n",
    "      ai_summarize(\n",
    "        CONCAT(\n",
    "          'There are ', CAST(num_of_blockers AS STRING), ' blockers. Briefly summarize the main theme or issue based on the latest blocker comment: ',\n",
    "          CASE \n",
    "            WHEN last_modified_blocker_category IS NOT NULL AND LENGTH(TRIM(last_modified_blocker_category)) > 0 \n",
    "              THEN CONCAT('Category: ', TRIM(last_modified_blocker_category), '. ')\n",
    "            ELSE ''\n",
    "          END,\n",
    "          COALESCE(TRIM(last_modified_blocker_comment), 'No blocker comment provided.')\n",
    "        ),\n",
    "        50\n",
    "      )\n",
    "    )\n",
    "  END AS blockers_summary\n",
    "FROM filtered_usecases;\n",
    "\n",
    "-- SELECT * FROM ai_blockers LIMIT 5;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3e37362-ce8b-43e0-8b8f-a44ee6aee1f8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Classify use case types"
    },
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Classify use case types using AI\n",
    "CREATE OR REPLACE TEMPORARY VIEW ai_usecase_types AS\n",
    "SELECT \n",
    "  usecase_id,\n",
    "  CASE\n",
    "    WHEN (usecase_name IS NOT NULL AND LENGTH(TRIM(usecase_name)) > 0)\n",
    "      OR (usecase_description IS NOT NULL AND LENGTH(TRIM(usecase_description)) > 0)\n",
    "    THEN COALESCE(\n",
    "      ai_classify(\n",
    "        concat('Usecase Name: ', coalesce(trim(usecase_name), '.'), ' Description: ', coalesce(trim(usecase_description), '.')),\n",
    "        array(\n",
    "          'Machine Learning', 'Generative AI', 'Data Warehousing', 'Migration AI', 'Migration Unity Catalog',\n",
    "          'Migration DWH', 'Migration ETL', 'Migration Streaming', 'Migration BI', \n",
    "          'BI', 'ETL', 'Governance', 'Streaming', 'Ingestion', 'Platform', 'Other'\n",
    "        )\n",
    "      ),\n",
    "      'Other'\n",
    "    )\n",
    "    ELSE 'Other'\n",
    "  END AS usecase_type,\n",
    "  \n",
    "  COALESCE(\n",
    "    ai_query(\n",
    "      'databricks-gemma-3-12b',\n",
    "      CONCAT(\n",
    "        'Given a use case name, description and industry imperative, return ONLY a concise business use case label (e.g. Fraud Detection, Inventory Forecasting, Customer Segmentation). Output exactly one short phrase, max 5 words, no punctuation or explanation. Usecase Name: ',\n",
    "        COALESCE(TRIM(usecase_name), 'Unknown'), \n",
    "        '. Description: ', COALESCE(TRIM(usecase_description), 'No description'),\n",
    "        '. Industry Imperative: ', COALESCE(TRIM(industry_imperative), 'No industry imperative')\n",
    "      ),\n",
    "      named_struct('max_tokens', 20, 'temperature', 0.0, 'failOnError', false)\n",
    "    ),\n",
    "    'Unknown Business Use Case'\n",
    "  ) AS business_usecase_type\n",
    "FROM filtered_usecases;\n",
    "\n",
    "-- SELECT * FROM ai_usecase_types LIMIT 5;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Generate executive soundbytes using AI\n",
    "CREATE OR REPLACE TEMPORARY VIEW ai_soundbyte AS\n",
    "SELECT\n",
    "  uct.usecase_id,\n",
    "  COALESCE(\n",
    "    ai_gen(\n",
    "      CONCAT(\n",
    "        'You are the Value Soundbite Agent. Your task is to generate a single elevator pitch sentence that connects a technical solution to a clear business outcome. You need to extract from the context\\n\\n',\n",
    "        'Customer name: ', COALESCE(f.account_name, 'Unknown'), '\\n',\n",
    "        'Technical Challenge (current pain/limitation): ', COALESCE(one.one_liner, 'Not specified'), '\\n',\n",
    "        'Technical Solution / Benefit (what the technology enables): ', COALESCE(uct.usecase_type, 'Not specified'), '\\n',\n",
    "        'Business Benefit (how analysts/users/teams work better, faster, cheaper): ', COALESCE(uct.business_usecase_type, 'Not specified'), '\\n',\n",
    "        'Business Goal (strategic outcome such as cost savings, revenue growth, margin improvement, risk reduction, etc.): ', COALESCE(ctx.context, 'Not specified'), '\\n\\n',\n",
    "        'Output:\\n',\n",
    "        'Write one concise, executive-ready sentence using this formula:\\n',\n",
    "        'By [implementing the solution] to tackle [technical challenge], [Customer] will [achieve business benefit] and [achieve business goal], enabling [strategic initiative/program] which will [ultimate business outcome].\\n\\n',\n",
    "        'Guidelines:\\n',\n",
    "        'Keep the sentence short, punchy, and outcome-driven.\\n',\n",
    "        'Focus on benefits, not features.\\n',\n",
    "        'Use business-friendly language (no jargon).'\n",
    "      )\n",
    "    ),\n",
    "    'No soundbyte generated'\n",
    "  ) AS soundbyte\n",
    "FROM ai_usecase_types uct\n",
    "LEFT JOIN filtered_usecases f ON uct.usecase_id = f.usecase_id\n",
    "LEFT JOIN ai_context ctx ON uct.usecase_id = ctx.usecase_id\n",
    "LEFT JOIN ai_oneliner one ON uct.usecase_id = one.usecase_id;\n",
    "\n",
    "-- SELECT soundbyte FROM ai_soundbyte LIMIT 5;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70a72677-3a14-4f51-9ab2-5eb6fc3e3b90",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Calculate confidence scores"
    },
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Generate AI confidence scores using MEDDPICC framework\n",
    "CREATE OR REPLACE TEMPORARY VIEW ai_confidence AS\n",
    "SELECT\n",
    "  f.usecase_id,\n",
    "  COALESCE(\n",
    "    ai_query(\n",
    "      'databricks-gemma-3-12b',\n",
    "      CONCAT(\n",
    "        'You are a Databricks Solutions Architect evaluating a customer use case and scoring its likelihood to reach production and generate sustained usage.\\n\\n',\n",
    "        'Rate the use case using these MEDDPICC-based dimensions (0â€“10 each):\\n',\n",
    "        '1. Pain â€“ Clear, urgent business problem?\\n',\n",
    "        '2. Champion â€“ Identified internal advocate?\\n',\n",
    "        '3. Implementation Plan â€“ Concrete next steps and ownership?\\n',\n",
    "        '4. Decision Process â€“ Clear decision path?\\n',\n",
    "        '5. Urgency â€“ Time pressure or deadline?\\n',\n",
    "        '6. Competition Awareness â€“ Known competitors?\\n',\n",
    "        '7. Measurable Impact â€“ Defined success metrics?\\n',\n",
    "        '8. Major Blockers â€“ Significant obstacles (higher score = **more blockers**).\\n\\n',\n",
    "        'Rules:\\n',\n",
    "        '- Base scores strictly on available evidence â€” do not speculate or imagine missing info.\\n',\n",
    "        '- If information is missing, assign a low score (â‰¤3) for that dimension.\\n',\n",
    "        '- Use these weightings: Pain 25%, Champion 20%, Implementation Plan 20%, Decision Process 10%, Urgency 10%, Competition Awareness 5%, Measurable Impact 2%, Major Blockers -8% (deductive).\\n',\n",
    "        '- Compute the total confidence_score as: (PainÃ—0.25 + ChampionÃ—0.20 + ImplementationPlanÃ—0.20 + DecisionProcessÃ—0.10 + UrgencyÃ—0.10 + CompetitionAwarenessÃ—0.05 + MeasurableImpactÃ—0.02 - MajorBlockersÃ—0.08) Ã— 10.\\n',\n",
    "        '- A perfect use case (10s across positive dimensions, 0 blockers) scores 100.\\n',\n",
    "        '- The total confidence_score must be between 0 and 100, rounded to the nearest multiple of 10.\\n\\n',\n",
    "        'Context:\\n',\n",
    "        'Account context: ', COALESCE(ctx.context, 'None'), '\\n',\n",
    "        'Use Case: ', COALESCE(one.one_liner, 'None'), '\\n',\n",
    "        'Next steps: ', COALESCE(ns.next_steps_summary, 'None'), '\\n',\n",
    "        'Implementation notes: ', COALESCE(imp.implementation_notes_summary, 'None'), '\\n',\n",
    "        'Blockers: ', COALESCE(blk.blockers_summary, 'None'), '\\n',\n",
    "        'Competition: ', COALESCE(f.competition_string, 'None'), '\\n\\n',\n",
    "        'Return output in **this exact format** (no text before or after):\\n\\n',\n",
    "        'CONFIDENCE_SCORE: [0â€“100 number]\\n',\n",
    "        'LEVEL: [High || Medium || Low]\\n',\n",
    "        'RATIONALE: [Brief explanation, 2â€“3 sentences max]\\n',\n",
    "        'DIMENSION_SCORES: Pain=x, Champion=x, ImplementationPlan=x, DecisionProcess=x, Urgency=x, CompetitionAwareness=x, MajorBlockers=x, MeasurableImpact=x'\n",
    "      ),\n",
    "      named_struct('max_tokens', 200, 'temperature', 0.0, 'top_p', 0.1, 'failOnError', false)\n",
    "    ),\n",
    "    'CONFIDENCE_SCORE: 0\\nLEVEL: Low\\nRATIONALE: No information provided.\\nDIMENSION_SCORES: Pain=0, Champion=0, ImplementationPlan=0, DecisionProcess=0, Urgency=0, CompetitionAwareness=0, MajorBlockers=0, MeasurableImpact=0'\n",
    "  ) AS ai_confidence_score_advanced\n",
    "FROM filtered_usecases f\n",
    "LEFT JOIN ai_context ctx ON f.usecase_id = ctx.usecase_id\n",
    "LEFT JOIN ai_oneliner one ON f.usecase_id = one.usecase_id\n",
    "LEFT JOIN ai_nextsteps ns ON f.usecase_id = ns.usecase_id\n",
    "LEFT JOIN ai_implementation imp ON f.usecase_id = imp.usecase_id\n",
    "LEFT JOIN ai_blockers blk ON f.usecase_id = blk.usecase_id;\n",
    "\n",
    "-- SELECT * FROM ai_confidence LIMIT 3;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54d32eda-212b-45b9-b189-4b26e3495008",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Extract scores"
    },
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Extract confidence score components using regex\n",
    "-- Apply override logic for use cases with >3 blockers\n",
    "CREATE OR REPLACE TEMPORARY VIEW parsed_confidence AS\n",
    "SELECT\n",
    "  ac.usecase_id,\n",
    "  ac.ai_confidence_score_advanced,\n",
    "  \n",
    "  -- Override confidence_score to 10 if >3 blockers, otherwise extract from AI response\n",
    "  CASE\n",
    "    WHEN COALESCE(f.num_of_blockers, 0) > 3 THEN 10\n",
    "    ELSE CAST(regexp_extract(ac.ai_confidence_score_advanced, 'CONFIDENCE_SCORE:\\\\s*(\\\\d+)', 1) AS INT)\n",
    "  END AS confidence_score,\n",
    "  \n",
    "  -- Override confidence_level to 'Low' if >3 blockers, otherwise extract from AI response\n",
    "  CASE\n",
    "    WHEN COALESCE(f.num_of_blockers, 0) > 3 THEN 'Low'\n",
    "    ELSE regexp_extract(ac.ai_confidence_score_advanced, 'LEVEL:\\\\s*(High|Medium|Low)', 1)\n",
    "  END AS confidence_level,\n",
    "  \n",
    "  -- Override rationale if >3 blockers, otherwise extract from AI response\n",
    "  CASE\n",
    "    WHEN COALESCE(f.num_of_blockers, 0) > 3 THEN 'The use case has too many blockers'\n",
    "    ELSE regexp_extract(ac.ai_confidence_score_advanced, 'RATIONALE:\\\\s*(.+?)\\\\s*DIMENSION_SCORES:', 1)\n",
    "  END AS rationale_for_confidence_score,\n",
    "  \n",
    "  -- Extract MEDDPICC dimension scores (no override - these come from AI analysis)\n",
    "  CAST(regexp_extract(ac.ai_confidence_score_advanced, 'Pain=(\\\\d+)', 1) AS INT) AS pain_score,\n",
    "  CAST(regexp_extract(ac.ai_confidence_score_advanced, 'Champion=(\\\\d+)', 1) AS INT) AS champion_score,\n",
    "  CAST(regexp_extract(ac.ai_confidence_score_advanced, 'ImplementationPlan=(\\\\d+)', 1) AS INT) AS implementationplan_score,\n",
    "  CAST(regexp_extract(ac.ai_confidence_score_advanced, 'DecisionProcess=(\\\\d+)', 1) AS INT) AS decisionprocess_score,\n",
    "  CAST(regexp_extract(ac.ai_confidence_score_advanced, 'Urgency=(\\\\d+)', 1) AS INT) AS urgency_score,\n",
    "  CAST(regexp_extract(ac.ai_confidence_score_advanced, 'CompetitionAwareness=(\\\\d+)', 1) AS INT) AS competitionawareness_score,\n",
    "  CAST(regexp_extract(ac.ai_confidence_score_advanced, 'MajorBlockers=(\\\\d+)', 1) AS INT) AS majorblockers_score,\n",
    "  CAST(regexp_extract(ac.ai_confidence_score_advanced, 'MeasurableImpact=(\\\\d+)', 1) AS INT) AS measurableimpact_score\n",
    "FROM ai_confidence ac\n",
    "LEFT JOIN filtered_usecases f ON ac.usecase_id = f.usecase_id;\n",
    "\n",
    "-- SELECT confidence_score, confidence_level, rationale_for_confidence_score, pain_score, champion_score FROM parsed_confidence LIMIT 5;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f61a8f0-f21e-4e4f-98f3-7e22a12ab5b7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Normalise confidence"
    },
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Apply normalized confidence level thresholds\n",
    "CREATE OR REPLACE TEMPORARY VIEW normalized_confidence AS\n",
    "SELECT\n",
    "  *,\n",
    "  CASE\n",
    "    WHEN confidence_score >= 75 THEN 'High'\n",
    "    WHEN confidence_score >= 45 THEN 'Medium'\n",
    "    WHEN confidence_score IS NOT NULL THEN 'Low'\n",
    "    ELSE 'Not computed'\n",
    "  END AS confidence_level_normalized\n",
    "FROM parsed_confidence;\n",
    "\n",
    "-- SELECT confidence_level_normalized, COUNT(*) AS count FROM normalized_confidence GROUP BY confidence_level_normalized ORDER BY count DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2f653fa-76b9-4013-a422-d2af843751f8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Add next best action"
    },
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Generate next best action recommendations\n",
    "CREATE OR REPLACE TEMPORARY VIEW ai_next_best_action AS\n",
    "SELECT\n",
    "  nc.usecase_id,\n",
    "  COALESCE(\n",
    "    ai_query(\n",
    "      'databricks-gpt-oss-20b',\n",
    "      CONCAT(\n",
    "        'You are a Databricks Solutions Architect helping an account team decide the next best action for a customer account and a specific use case.\\n',\n",
    "        'Inputs:\\n',\n",
    "        'Account context: ', COALESCE(ctx.context, 'None'), '\\n',\n",
    "        'Use Case: ', COALESCE(one.one_liner, 'None'), '\\n',\n",
    "        'Next steps summary: ', COALESCE(ns.next_steps_summary, 'None'), '\\n',\n",
    "        'Implementation notes: ', COALESCE(imp.implementation_notes_summary, 'None'), '\\n',\n",
    "        'Blockers: ', COALESCE(blk.blockers_summary, 'None'), '\\n',\n",
    "        'Competition: ', COALESCE(f.competition_string, 'None'), '\\n',\n",
    "        'MEDDPICC dimension scores: Pain=', COALESCE(CAST(nc.pain_score AS STRING), 'None'),\n",
    "        ', Champion=', COALESCE(CAST(nc.champion_score AS STRING), 'None'),\n",
    "        ', ImplementationPlan=', COALESCE(CAST(nc.implementationplan_score AS STRING), 'None'),\n",
    "        ', DecisionProcess=', COALESCE(CAST(nc.decisionprocess_score AS STRING), 'None'),\n",
    "        ', Urgency=', COALESCE(CAST(nc.urgency_score AS STRING), 'None'),\n",
    "        ', CompetitionAwareness=', COALESCE(CAST(nc.competitionawareness_score AS STRING), 'None'),\n",
    "        ', MajorBlockers=', COALESCE(CAST(nc.majorblockers_score AS STRING), 'None'),\n",
    "        ', MeasurableImpact=', COALESCE(CAST(nc.measurableimpact_score AS STRING), 'None'), '\\n',\n",
    "        'Overall confidence level: ', COALESCE(nc.confidence_level_normalized, 'None'), '\\n\\n',\n",
    "        'Rules:\\n',\n",
    "        '1. Base your recommendation strictly on the evidence provided â€” do not assume missing information.\\n',\n",
    "        '2. Prioritize actions that maximize the likelihood of a successful go-live and reduce blockers.\\n',\n",
    "        '3. If Pain, Champion, or Implementation Plan is low (<5/10), suggest actions to strengthen these dimensions first.\\n',\n",
    "        '4. If Major Blockers > 5/10, suggest actions to mitigate or remove the blockers.\\n',\n",
    "        '5. If Urgency is high (>7/10), prioritize time-sensitive actions.\\n',\n",
    "        '6. Provide one concise, actionable next step, written as if for the account team to execute within the next week.\\n',\n",
    "        '7. Keep your answer short â€” 1â€“2 sentences max.\\n',\n",
    "        '8. Be deterministic: always follow the rules exactly and do not vary wording unnecessarily.\\n\\n',\n",
    "        'Return output in this exact format (no extra text):\\n\\n',\n",
    "        'NEXT_BEST_ACTION: [Short, actionable recommendation for the account team]\\n',\n",
    "        'RATIONALE: [Brief explanation linking the action to the MEDDPICC scores and blockers, â‰¤2 sentences]'\n",
    "      ),\n",
    "      named_struct('max_tokens', 200, 'temperature', 0.0, 'top_p', 0.1, 'failOnError', false)\n",
    "    ),\n",
    "    'NEXT_BEST_ACTION: Review MEDDPICC evidence and address missing information.\\nRATIONALE: No sufficient context or scores provided to generate a specific action.'\n",
    "  ) AS next_best_action_recommendation\n",
    "FROM normalized_confidence nc\n",
    "LEFT JOIN filtered_usecases f ON nc.usecase_id = f.usecase_id\n",
    "LEFT JOIN ai_context ctx ON nc.usecase_id = ctx.usecase_id\n",
    "LEFT JOIN ai_oneliner one ON nc.usecase_id = one.usecase_id\n",
    "LEFT JOIN ai_nextsteps ns ON nc.usecase_id = ns.usecase_id\n",
    "LEFT JOIN ai_implementation imp ON nc.usecase_id = imp.usecase_id\n",
    "LEFT JOIN ai_blockers blk ON nc.usecase_id = blk.usecase_id;\n",
    "\n",
    "-- SELECT * FROM ai_next_best_action LIMIT 3;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "beaa58df-63dd-4302-8f6e-914bddf5677e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Classify slippage"
    },
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Classify slippage and acceleration categories\n",
    "CREATE OR REPLACE TEMPORARY VIEW ai_slippage_acceleration AS\n",
    "SELECT \n",
    "  nc.usecase_id,\n",
    "  \n",
    "  -- Flag use cases likely to slip\n",
    "  CASE \n",
    "    WHEN nc.confidence_level_normalized = 'Medium' THEN true\n",
    "    ELSE false\n",
    "  END AS likely_to_slip,\n",
    "  \n",
    "  -- Classify slippage category\n",
    "  CASE\n",
    "    WHEN nc.confidence_level_normalized = 'Medium'\n",
    "    THEN COALESCE(\n",
    "      ai_classify(\n",
    "        CONCAT(\n",
    "          'You are a Databricks Senior Solutions Architect.\\n',\n",
    "          'Classify the PRIMARY reason this use case is likely to slip. Choose exactly ONE from:\\n',\n",
    "          '[Technical, Business, Stakeholder, Budget, Project Timelines, Data, Integration, Partner, Hyperscaler, Competition, Other, External dependencies]\\n\\n',\n",
    "          'Decision Rules:\\n',\n",
    "          '- Technical â†’ missing features, blockers, or bugs.\\n',\n",
    "          '- Business â†’ shifting priorities or unclear value.\\n',\n",
    "          '- Stakeholder â†’ low buy-in or sponsor turnover.\\n',\n",
    "          '- Budget â†’ funding or approval delays.\\n',\n",
    "          '- Project Timelines â†’ missed milestones or dependencies.\\n',\n",
    "          '- Data â†’ quality, access, or integration issues.\\n',\n",
    "          '- Integration â†’ tooling or system connectivity issues.\\n',\n",
    "          '- Partner â†’ bandwidth or enablement gaps.\\n',\n",
    "          '- Hyperscaler â†’ regional, quota, or policy constraints.\\n',\n",
    "          '- Competition â†’ market or rival-driven reprioritization.\\n',\n",
    "          '- External dependencies â†’ third-party or customer-side blockers.\\n',\n",
    "          '- Other â†’ none of the above.\\n\\n',\n",
    "          'Inputs:\\n',\n",
    "          'Confidence Score Rationale: ', COALESCE(LEFT(nc.rationale_for_confidence_score, 200), 'N/A'), '\\n',\n",
    "          'Next Step: ', COALESCE(LEFT(nba.next_best_action_recommendation, 200), 'N/A')\n",
    "        ),\n",
    "        ARRAY(\n",
    "          'Technical', 'Business', 'Stakeholder', 'Budget', 'Project Timelines', 'Data', 'Integration', 'Partner', 'Hyperscaler', 'Competition', 'Other', 'External dependencies'\n",
    "        )\n",
    "      ),\n",
    "      'Unable to determine slippage category'\n",
    "    )\n",
    "    ELSE 'N/A'\n",
    "  END AS slippage_category,\n",
    "  \n",
    "  -- Flag use cases that can be accelerated\n",
    "  CASE \n",
    "    WHEN nc.confidence_level_normalized IN ('Medium', 'High') THEN true\n",
    "    ELSE false\n",
    "  END AS can_be_accelerated,\n",
    "  \n",
    "  -- Classify acceleration category\n",
    "  CASE\n",
    "    WHEN nc.confidence_level_normalized IN ('Medium', 'High') THEN \n",
    "      COALESCE(\n",
    "        ai_classify(\n",
    "          CONCAT(\n",
    "            'You are a Databricks Senior Solutions Architect.\\n',\n",
    "            'Classify the PRIMARY reason this use case could be accelerated.\\n',\n",
    "            'Choose exactly ONE label from:\\n',\n",
    "            '[Implementation Planning, Resource Allocation, Stakeholder Engagement, Technical Optimization, Partnership Leverage, Governance and Support, Innovation and Technology Enablement, Capability Development, Funding, Other]\\n\\n',\n",
    "            'Decision rules:\\n',\n",
    "            '- Implementation Planning â†’ clarifying the WHAT/WHEN/WHO (critical path, milestones, owners).\\n',\n",
    "            '- Resource Allocation â†’ people/tools/compute NOW.\\n',\n",
    "            '- Stakeholder Engagement â†’ alignment, cadence, or decisions.\\n',\n",
    "            '- Technical Optimization â†’ performance, architecture, integration tuning.\\n',\n",
    "            '- Innovation and Technology Enablement â†’ templates, automation, AI accelerators.\\n',\n",
    "            '- Governance and Support â†’ steering, dashboards, SLAs, support.\\n',\n",
    "            '- Capability Development â†’ training, upskilling, knowledge transfer.\\n',\n",
    "            '- Partnership Leverage â†’ partner expertise/assets as key lever.\\n',\n",
    "            '- Funding â†’ securing or expediting budget, approvals, resources.\\n',\n",
    "            '- Other â†’ none of the above.\\n\\n',\n",
    "            'Return exactly one of the labels above â€” no punctuation or explanation.\\n\\n',\n",
    "            'Context:\\n',\n",
    "            'Confidence Score Rationale: ', COALESCE(LEFT(nc.rationale_for_confidence_score, 200), 'N/A'), '\\n',\n",
    "            'Next Step: ', COALESCE(LEFT(nba.next_best_action_recommendation, 200), 'N/A')\n",
    "          ),\n",
    "          ARRAY(\n",
    "            'Implementation Planning', 'Resource Allocation', 'Stakeholder Engagement', 'Technical Optimization', \n",
    "            'Partnership Leverage', 'Governance and Support', 'Innovation and Technology Enablement', \n",
    "            'Capability Development', 'Funding', 'Other'\n",
    "          )\n",
    "        ),\n",
    "        'Unable to determine acceleration category'\n",
    "      )\n",
    "    ELSE 'N/A'\n",
    "  END AS accel_category\n",
    "FROM normalized_confidence nc\n",
    "LEFT JOIN ai_next_best_action nba ON nc.usecase_id = nba.usecase_id;\n",
    "\n",
    "-- SELECT likely_to_slip, slippage_category, can_be_accelerated, accel_category FROM ai_slippage_acceleration LIMIT 5;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5006ecfa-fdc8-4dcd-8e4f-b8f6b14dc2d5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create complete AI output view"
    },
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Join all AI enrichments - keep only minimal columns\n",
    "-- Can always re-join to source table on usecase_id for other fields\n",
    "CREATE OR REPLACE TEMPORARY VIEW enriched_results AS\n",
    "SELECT \n",
    "  -- Core identifiers and timestamps\n",
    "  base.usecase_id,\n",
    "  base.last_modified_date,\n",
    "  CURRENT_DATE() AS piq_last_updated,\n",
    "  \n",
    "  -- Fields needed for AI inference (kept for reference)\n",
    "  base.competition_string,\n",
    "  base.num_of_blockers,\n",
    "  -- AI enriched fields\n",
    "  ctx.context,\n",
    "  one.one_liner,\n",
    "  ns.next_steps_summary,\n",
    "  imp.implementation_notes_summary,\n",
    "  blk.blockers_summary,\n",
    "  uct.usecase_type,\n",
    "  uct.business_usecase_type,\n",
    "  sb.soundbyte,\n",
    "  \n",
    "  -- Confidence scoring\n",
    "  nc.ai_confidence_score_advanced,\n",
    "  nc.confidence_score,\n",
    "  nc.confidence_level,\n",
    "  nc.rationale_for_confidence_score,\n",
    "  nc.pain_score,\n",
    "  nc.champion_score,\n",
    "  nc.implementationplan_score,\n",
    "  nc.decisionprocess_score,\n",
    "  nc.urgency_score,\n",
    "  nc.competitionawareness_score,\n",
    "  nc.majorblockers_score,\n",
    "  nc.measurableimpact_score,\n",
    "  nc.confidence_level_normalized,\n",
    "  \n",
    "  -- Recommendations and classifications\n",
    "  nba.next_best_action_recommendation,\n",
    "  sa.likely_to_slip,\n",
    "  sa.slippage_category,\n",
    "  sa.can_be_accelerated,\n",
    "  sa.accel_category\n",
    "FROM filtered_usecases base\n",
    "LEFT JOIN ai_context ctx ON base.usecase_id = ctx.usecase_id\n",
    "LEFT JOIN ai_oneliner one ON base.usecase_id = one.usecase_id\n",
    "LEFT JOIN ai_nextsteps ns ON base.usecase_id = ns.usecase_id\n",
    "LEFT JOIN ai_implementation imp ON base.usecase_id = imp.usecase_id\n",
    "LEFT JOIN ai_blockers blk ON base.usecase_id = blk.usecase_id\n",
    "LEFT JOIN ai_usecase_types uct ON base.usecase_id = uct.usecase_id\n",
    "LEFT JOIN ai_soundbyte sb ON base.usecase_id = sb.usecase_id\n",
    "LEFT JOIN normalized_confidence nc ON base.usecase_id = nc.usecase_id\n",
    "LEFT JOIN ai_next_best_action nba ON base.usecase_id = nba.usecase_id\n",
    "LEFT JOIN ai_slippage_acceleration sa ON base.usecase_id = sa.usecase_id;\n",
    "\n",
    "-- Show count of enriched records\n",
    "-- SELECT \n",
    "--   COUNT(*) AS total_enriched_records,\n",
    "--   COUNT(context) AS with_context,\n",
    "--   COUNT(confidence_score) AS with_confidence_score\n",
    "-- FROM enriched_results;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04f246a6-1b2d-4c74-9d22-601de4d07f00",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Merge results into target"
    },
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Merge enriched results into target table\n",
    "-- Updates when source last_modified_date is newer, always updates piq_last_updated\n",
    "MERGE INTO IDENTIFIER(:catalog || '.' || :schema || '.pipelineiq') AS target\n",
    "USING enriched_results AS source\n",
    "ON target.usecase_id = source.usecase_id\n",
    "WHEN MATCHED AND source.last_modified_date > target.last_modified_date THEN\n",
    "  UPDATE SET *\n",
    "WHEN NOT MATCHED THEN\n",
    "  INSERT *;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5367791-e161-4ab5-ae78-15059492abd3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Update metadata if needed"
    },
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Add table properties for tracking AI model and processing metadata\n",
    "ALTER TABLE IDENTIFIER(:catalog || '.' || :schema || '.pipelineiq') SET TBLPROPERTIES (\n",
    "  'ai.model.primary' = 'databricks-gpt-oss-20b',\n",
    "  'ai.model.confidence' = 'databricks-gemma-3-12b',\n",
    "  'ai.model.business_usecase' = 'databricks-gemma-3-12b',\n",
    "  -- 'ai.generation.timestamp' = CURRENT_DATE(), -- replaced by the piq_last_updated field\n",
    "  'ai.prompt.version' = 'v1.4',\n",
    "  'pipeline.type' = 'incremental',\n",
    "  'quality' = 'gold'\n",
    ");\n",
    "\n",
    "-- SELECT 'Metadata added to table: ' || :catalog || '.' || :schema || '.pipelineiq' AS status;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5eb1e685-fb86-43c2-b11c-11566c7a86ee",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Verify update"
    },
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Verify the merge results\n",
    "SELECT \n",
    "  'Total Records' AS metric,\n",
    "  COUNT(*) AS count\n",
    "FROM IDENTIFIER(:catalog || '.' || :schema || '.pipelineiq')\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "  'Records with AI Enrichment' AS metric,\n",
    "  COUNT(*) AS count\n",
    "FROM IDENTIFIER(:catalog || '.' || :schema || '.pipelineiq')\n",
    "WHERE context IS NOT NULL\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "  'Records with Confidence Score' AS metric,\n",
    "  COUNT(*) AS count\n",
    "FROM IDENTIFIER(:catalog || '.' || :schema || '.pipelineiq')\n",
    "WHERE confidence_score IS NOT NULL\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "  'High Confidence' AS metric,\n",
    "  COUNT(*) AS count\n",
    "FROM IDENTIFIER(:catalog || '.' || :schema || '.pipelineiq')\n",
    "WHERE confidence_level_normalized = 'High'\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "  'Medium Confidence' AS metric,\n",
    "  COUNT(*) AS count\n",
    "FROM IDENTIFIER(:catalog || '.' || :schema || '.pipelineiq')\n",
    "WHERE confidence_level_normalized = 'Medium'\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "  'Low Confidence' AS metric,\n",
    "  COUNT(*) AS count\n",
    "FROM IDENTIFIER(:catalog || '.' || :schema || '.pipelineiq')\n",
    "WHERE confidence_level_normalized = 'Low';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4a627a1-7b78-4d03-b43e-1470ead42d39",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Verify updates over time"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select piq_last_updated, count(*) from IDENTIFIER(:catalog || '.' || :schema || '.pipelineiq') group by all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b046b0a-a213-4120-9c17-e6b5705b7f29",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Data sample"
    },
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Show sample of enriched records (recently processed)\n",
    "-- Note: To see usecase_name and other source fields, join back to core_usecase_curated on usecase_id\n",
    "SELECT \n",
    "  usecase_id,\n",
    "  one_liner,\n",
    "  confidence_score,\n",
    "  confidence_level_normalized,\n",
    "  usecase_type,\n",
    "  business_usecase_type,\n",
    "  likely_to_slip,\n",
    "  slippage_category,\n",
    "  can_be_accelerated,\n",
    "  accel_category,\n",
    "  last_modified_date,\n",
    "  piq_last_updated\n",
    "FROM IDENTIFIER(:catalog || '.' || :schema || '.pipelineiq')\n",
    "WHERE piq_last_updated = CURRENT_DATE()\n",
    "ORDER BY confidence_score DESC\n",
    "LIMIT 10;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b4417a3-2e65-47a4-8f69-434ba826f4d0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create PIQ view"
    },
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Create pipelineiq_view matching Confidence Analysis structure\n",
    "-- This view joins PipelineIQ AI enrichments with source data and applies look-ahead filters\n",
    "-- Filters are applied to exclude closed/lost use cases and focus on active pipeline\n",
    "-- DEVELOPMENT NOTE: âš ï¸ Variable values are not allowed, if you update min DBUs or the window dates, you need to update them here too!!\n",
    "use catalog IDENTIFIER(:catalog);\n",
    "use schema IDENTIFIER(:schema);\n",
    "CREATE OR REPLACE VIEW IDENTIFIER(:catalog || '.' || :schema || '.pipelineiq_view') AS\n",
    "SELECT \n",
    "  -- Original fields from source (with transformations)\n",
    "  src.snapshot_date,\n",
    "  CASE \n",
    "    WHEN src.field_manager IS NULL THEN 'FLM not assigned'\n",
    "    ELSE src.field_manager\n",
    "  END AS field_manager,\n",
    "  src.account_name,\n",
    "  piq.usecase_id,\n",
    "  src.usecase_name,\n",
    "  src.last_modified_date,\n",
    "  src.account_executive,\n",
    "  CASE \n",
    "    WHEN src.account_solution_architect IS NULL THEN 'SA not assigned'\n",
    "    ELSE src.account_solution_architect\n",
    "  END AS account_solution_architect,\n",
    "  src.stage,\n",
    "  src.target_cloud,\n",
    "  src.primary_competitor,\n",
    "  src.target_live_date,\n",
    "  src.target_onboarding_date,\n",
    "  src.estimated_monthly_dollar_dbus,\n",
    "  src.usecase_description,\n",
    "  src.demand_plan_stage_next_steps,\n",
    "  src.implementation_notes,\n",
    "  CASE\n",
    "    WHEN src.sales_region IS NOT NULL THEN src.sales_region\n",
    "    WHEN src.sales_region IS NULL AND src.business_unit IS NOT NULL THEN src.business_unit\n",
    "    WHEN src.sales_region IS NULL AND src.business_unit IS NULL THEN 'No assigned'\n",
    "    ELSE 'No assigned'\n",
    "  END AS sales_region,\n",
    "  src.sales_subregion_level_1,\n",
    "  src.sales_subregion_level_2,\n",
    "  src.sales_subregion_level_3,\n",
    "  src.sales_subregion_level_4,\n",
    "  src.sales_manager,\n",
    "  src.sales_leader,\n",
    "  src.field_leader,\n",
    "  src.use_case_product,\n",
    "  src.blockers_last_modified_date,\n",
    "  src.sdr_bdr_notes,\n",
    "  src.business_impact,\n",
    "  src.business_outcome_description,\n",
    "  src.ae_authority,\n",
    "  src.ae_money_budget,\n",
    "  src.business_unit,\n",
    "  piq.num_of_blockers,\n",
    "  src.last_modified_blocker_category,\n",
    "  src.last_modified_blocker_comment,\n",
    "  src.competition_string,\n",
    "  \n",
    "  -- AI-generated fields\n",
    "  piq.context,\n",
    "  piq.one_liner,\n",
    "  piq.next_steps_summary,\n",
    "  piq.implementation_notes_summary,\n",
    "  piq.blockers_summary,\n",
    "  piq.usecase_type,\n",
    "  piq.business_usecase_type,\n",
    "  piq.soundbyte,\n",
    "  \n",
    "  -- Computed staleness flag (always relative to current date)\n",
    "  CASE \n",
    "    WHEN src.last_modified_date < DATE_SUB(CURRENT_DATE(), 14) \n",
    "    THEN true \n",
    "    ELSE false \n",
    "  END AS is_stale,\n",
    "  \n",
    "  piq.ai_confidence_score_advanced,\n",
    "  piq.confidence_score,\n",
    "  piq.confidence_level,\n",
    "  piq.rationale_for_confidence_score,\n",
    "  piq.pain_score,\n",
    "  piq.champion_score,\n",
    "  piq.implementationplan_score,\n",
    "  piq.decisionprocess_score,\n",
    "  piq.urgency_score,\n",
    "  piq.competitionawareness_score,\n",
    "  piq.majorblockers_score,\n",
    "  piq.measurableimpact_score,\n",
    "  piq.confidence_level_normalized,\n",
    "  piq.next_best_action_recommendation,\n",
    "  piq.likely_to_slip,\n",
    "  piq.slippage_category,\n",
    "  piq.can_be_accelerated,\n",
    "  piq.accel_category,\n",
    "  \n",
    "  -- Set vertical to 'Not specified' if null\n",
    "  COALESCE(src.vertical, 'Not specified') AS vertical\n",
    "FROM pipelineiq piq\n",
    "INNER JOIN main.gtm_data.core_usecase_curated src \n",
    "  ON piq.usecase_id = src.usecase_id\n",
    "WHERE \n",
    "  -- Apply look-ahead filters to focus on active pipeline\n",
    "  -- These filters prevent closed/lost use cases from appearing in the view\n",
    "  src.estimated_monthly_dollar_dbus >= 1000\n",
    "  AND src.stage NOT IN ('U1', 'Lost', 'Closed', 'Disqualified')\n",
    "  AND src.target_live_date BETWEEN CURRENT_DATE() AND ADD_MONTHS(CURRENT_DATE(), 6);\n",
    "\n",
    "-- Add column comments for key fields\n",
    "COMMENT ON VIEW IDENTIFIER(:catalog || '.' || :schema || '.pipelineiq_view') IS 'Business-facing view of PipelineIQ with cleaned recommendation labels, normalized verticals, and presentation-ready AI enrichment. Applies look-ahead filters to focus on active pipeline use cases.';\n",
    "\n",
    "-- Add table properties\n",
    "ALTER VIEW IDENTIFIER(:catalog || '.' || :schema || '.pipelineiq_view') SET TBLPROPERTIES (\n",
    "  'ai.pipeline.version' = 'v1.4',\n",
    "  'ai.model.primary' = 'databricks-gpt-oss-20b',\n",
    "  'ai.model.confidence' = 'databricks-gemma-3-12b',\n",
    "  'ai.model.business_usecase' = 'databricks-gemma-3-12b',\n",
    "  'ai.view.purpose' = 'Executive insights and reporting',\n",
    "  'pipeline.type' = 'incremental',\n",
    "  'quality' = 'gold'\n",
    ");\n",
    "\n",
    "-- Display the first 10 lines of the view\n",
    "SELECT * FROM IDENTIFIER(:catalog || '.' || :schema || '.pipelineiq_view') LIMIT 10;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Create field manager summary view for executive reporting\n",
    "-- Aggregates use case metrics, confidence distribution, and top categories by field manager\n",
    "CREATE OR REPLACE VIEW IDENTIFIER(:catalog || '.' || :schema || '.field_manager_summary_view') (\n",
    "  snapshot_date,\n",
    "  field_manager,\n",
    "  sales_region,\n",
    "  sales_subregion_level_1,\n",
    "  sales_subregion_level_2,\n",
    "  sales_subregion_level_3,\n",
    "  sales_subregion_level_4,\n",
    "  total_use_cases,\n",
    "  total_estimated_monthly_dbu,\n",
    "  high_confidence_count,\n",
    "  high_confidence_pct,\n",
    "  medium_confidence_count,\n",
    "  medium_confidence_pct,\n",
    "  low_confidence_count,\n",
    "  low_confidence_pct,\n",
    "  slip_usecase_count,\n",
    "  slip_total_monthly_dbu,\n",
    "  accel_usecase_count,\n",
    "  accel_total_monthly_dbu,\n",
    "  stale_usecase_count,\n",
    "  stale_total_monthly_dbu,\n",
    "  u3_stale_usecase_count,\n",
    "  u3_stale_total_monthly_dbu,\n",
    "  u5_stale_usecase_count,\n",
    "  u5_stale_total_monthly_dbu,\n",
    "  one_blocker_usecase_count,\n",
    "  one_blocker_total_monthly_dbu,\n",
    "  azure_medhigh_usecase_count,\n",
    "  azure_medhigh_total_monthly_dbu,\n",
    "  threeplus_blocker_usecase_count,\n",
    "  threeplus_blocker_total_monthly_dbu,\n",
    "  top1_usecase_type,\n",
    "  top1_usecase_type_count,\n",
    "  top1_usecase_type_monthly_dbu,\n",
    "  top2_usecase_type,\n",
    "  top2_usecase_type_count,\n",
    "  top2_usecase_type_monthly_dbu,\n",
    "  top3_usecase_type,\n",
    "  top3_usecase_type_count,\n",
    "  top3_usecase_type_monthly_dbu,\n",
    "  top1_slippage_category,\n",
    "  top1_slip_usecase_count,\n",
    "  top1_slippage_category_description,\n",
    "  top2_slippage_category,\n",
    "  top2_slip_usecase_count,\n",
    "  top2_slippage_category_description,\n",
    "  top3_slippage_category,\n",
    "  top3_slip_usecase_count,\n",
    "  top3_slippage_category_description,\n",
    "  top1_accel_category,\n",
    "  top1_accel_usecase_count,\n",
    "  top1_accel_category_description,\n",
    "  top2_accel_category,\n",
    "  top2_accel_usecase_count,\n",
    "  top2_accel_category_description,\n",
    "  top3_accel_category,\n",
    "  top3_accel_usecase_count,\n",
    "  top3_accel_category_description,\n",
    "  top1_vertical,\n",
    "  top1_vertical_usecase_count,\n",
    "  top2_vertical,\n",
    "  top2_vertical_usecase_count,\n",
    "  top3_vertical,\n",
    "  top3_vertical_usecase_count,\n",
    "  name,\n",
    "  surname,\n",
    "  generated_email,\n",
    "  email,\n",
    "  email_status\n",
    ") AS\n",
    "WITH field_manager_summary AS (\n",
    "  SELECT\n",
    "    any_value(snapshot_date) as snapshot_date,\n",
    "    field_manager,\n",
    "    any_value(sales_region) as sales_region,\n",
    "    any_value(sales_subregion_level_1) as sales_subregion_level_1,\n",
    "    any_value(sales_subregion_level_2) as sales_subregion_level_2,\n",
    "    any_value(sales_subregion_level_3) as sales_subregion_level_3,\n",
    "    any_value(sales_subregion_level_4) as sales_subregion_level_4,\n",
    "    COUNT(*) AS total_use_cases,\n",
    "    SUM(estimated_monthly_dollar_dbus) AS total_estimated_monthly_dbu,\n",
    "    SUM(CASE WHEN confidence_level_normalized = 'High' THEN 1 ELSE 0 END) AS high_confidence_count,\n",
    "    ROUND(100.0 * SUM(CASE WHEN confidence_level_normalized = 'High' THEN 1 ELSE 0 END) / COUNT(*), 2) AS high_confidence_pct,\n",
    "    SUM(CASE WHEN confidence_level_normalized = 'Medium' THEN 1 ELSE 0 END) AS medium_confidence_count,\n",
    "    ROUND(100.0 * SUM(CASE WHEN confidence_level_normalized = 'Medium' THEN 1 ELSE 0 END) / COUNT(*), 2) AS medium_confidence_pct,\n",
    "    SUM(CASE WHEN confidence_level_normalized = 'Low' THEN 1 ELSE 0 END) AS low_confidence_count,\n",
    "    ROUND(100.0 * SUM(CASE WHEN confidence_level_normalized = 'Low' THEN 1 ELSE 0 END) / COUNT(*), 2) AS low_confidence_pct,\n",
    "    SUM(CASE WHEN likely_to_slip = TRUE THEN 1 ELSE 0 END) AS slip_usecase_count,\n",
    "    SUM(CASE WHEN likely_to_slip = TRUE THEN estimated_monthly_dollar_dbus ELSE 0 END) AS slip_total_monthly_dbu,\n",
    "    SUM(CASE WHEN can_be_accelerated = TRUE THEN 1 ELSE 0 END) AS accel_usecase_count,\n",
    "    SUM(CASE WHEN can_be_accelerated = TRUE THEN estimated_monthly_dollar_dbus ELSE 0 END) AS accel_total_monthly_dbu,\n",
    "    SUM(CASE WHEN stage IN ('U3', 'U5') AND last_modified_date < date_sub(current_date(), 14) THEN 1 ELSE 0 END) AS stale_usecase_count,\n",
    "    SUM(CASE WHEN stage IN ('U3', 'U5') AND last_modified_date < date_sub(current_date(), 14) THEN estimated_monthly_dollar_dbus ELSE 0 END) AS stale_total_monthly_dbu,\n",
    "    SUM(CASE WHEN stage = 'U3' AND last_modified_date < date_sub(current_date(), 14) THEN 1 ELSE 0 END) AS u3_stale_usecase_count,\n",
    "    SUM(CASE WHEN stage = 'U3' AND last_modified_date < date_sub(current_date(), 14) THEN estimated_monthly_dollar_dbus ELSE 0 END) AS u3_stale_total_monthly_dbu,\n",
    "    SUM(CASE WHEN stage = 'U5' AND last_modified_date < date_sub(current_date(), 14) THEN 1 ELSE 0 END) AS u5_stale_usecase_count,\n",
    "    SUM(CASE WHEN stage = 'U5' AND last_modified_date < date_sub(current_date(), 14) THEN estimated_monthly_dollar_dbus ELSE 0 END) AS u5_stale_total_monthly_dbu,\n",
    "    SUM(CASE WHEN num_of_blockers = 1 THEN 1 ELSE 0 END) AS one_blocker_usecase_count,\n",
    "    SUM(CASE WHEN num_of_blockers = 1 THEN estimated_monthly_dollar_dbus ELSE 0 END) AS one_blocker_total_monthly_dbu,\n",
    "    SUM(CASE WHEN stage IN ('U2', 'U4', 'U5') AND confidence_level_normalized IN ('Medium', 'High') AND lower(target_cloud) LIKE '%azure%' THEN 1 ELSE 0 END) AS azure_medhigh_usecase_count,\n",
    "    SUM(CASE WHEN stage IN ('U2', 'U4', 'U5') AND confidence_level_normalized IN ('Medium', 'High') AND lower(target_cloud) LIKE '%azure%' THEN estimated_monthly_dollar_dbus ELSE 0 END) AS azure_medhigh_total_monthly_dbu,\n",
    "    SUM(CASE WHEN num_of_blockers >= 3 THEN 1 ELSE 0 END) AS threeplus_blocker_usecase_count,\n",
    "    SUM(CASE WHEN num_of_blockers >= 3 THEN estimated_monthly_dollar_dbus ELSE 0 END) AS threeplus_blocker_total_monthly_dbu\n",
    "  FROM IDENTIFIER(:catalog || '.' || :schema || '.pipelineiq_view')\n",
    "  GROUP BY field_manager\n",
    "),\n",
    "slip_categories AS (\n",
    "  SELECT\n",
    "    field_manager,\n",
    "    sc.slippage_category,\n",
    "    COUNT(*) AS slip_usecase_count,\n",
    "    ROW_NUMBER() OVER (PARTITION BY field_manager ORDER BY COUNT(*) DESC) AS rn\n",
    "  FROM IDENTIFIER(:catalog || '.' || :schema || '.pipelineiq_view') sc\n",
    "  WHERE likely_to_slip = TRUE\n",
    "  GROUP BY field_manager, slippage_category\n",
    "),\n",
    "accel_categories AS (\n",
    "  SELECT\n",
    "    field_manager,\n",
    "    ac.accel_category,\n",
    "    COUNT(*) AS accel_usecase_count,\n",
    "    ROW_NUMBER() OVER (PARTITION BY field_manager ORDER BY COUNT(*) DESC) AS rn\n",
    "  FROM IDENTIFIER(:catalog || '.' || :schema || '.pipelineiq_view') ac\n",
    "  WHERE can_be_accelerated = TRUE\n",
    "  GROUP BY field_manager, accel_category\n",
    "),\n",
    "usecase_type_ranked AS (\n",
    "  SELECT\n",
    "    field_manager,\n",
    "    usecase_type,\n",
    "    COUNT(*) AS usecase_type_count,\n",
    "    SUM(estimated_monthly_dollar_dbus) AS usecase_type_monthly_dbu,\n",
    "    ROW_NUMBER() OVER (PARTITION BY field_manager ORDER BY SUM(estimated_monthly_dollar_dbus) DESC) AS rn\n",
    "  FROM IDENTIFIER(:catalog || '.' || :schema || '.pipelineiq_view')\n",
    "  GROUP BY field_manager, usecase_type\n",
    "),\n",
    "vertical_categories AS (\n",
    "  SELECT\n",
    "    field_manager,\n",
    "    vertical,\n",
    "    COUNT(*) AS vertical_usecase_count,\n",
    "    ROW_NUMBER() OVER (PARTITION BY field_manager ORDER BY COUNT(*) DESC) AS rn\n",
    "  FROM IDENTIFIER(:catalog || '.' || :schema || '.pipelineiq_view')\n",
    "  GROUP BY field_manager, vertical\n",
    ")\n",
    "SELECT\n",
    "  fms.snapshot_date,\n",
    "  fms.field_manager,\n",
    "  fms.sales_region,\n",
    "  fms.sales_subregion_level_1,\n",
    "  fms.sales_subregion_level_2,\n",
    "  fms.sales_subregion_level_3,\n",
    "  fms.sales_subregion_level_4,\n",
    "  fms.total_use_cases,\n",
    "  fms.total_estimated_monthly_dbu,\n",
    "  fms.high_confidence_count,\n",
    "  fms.high_confidence_pct,\n",
    "  fms.medium_confidence_count,\n",
    "  fms.medium_confidence_pct,\n",
    "  fms.low_confidence_count,\n",
    "  fms.low_confidence_pct,\n",
    "  fms.slip_usecase_count,\n",
    "  fms.slip_total_monthly_dbu,\n",
    "  fms.accel_usecase_count,\n",
    "  fms.accel_total_monthly_dbu,\n",
    "  fms.stale_usecase_count,\n",
    "  fms.stale_total_monthly_dbu,\n",
    "  fms.u3_stale_usecase_count,\n",
    "  fms.u3_stale_total_monthly_dbu,\n",
    "  fms.u5_stale_usecase_count,\n",
    "  fms.u5_stale_total_monthly_dbu,\n",
    "  fms.one_blocker_usecase_count,\n",
    "  fms.one_blocker_total_monthly_dbu,\n",
    "  fms.azure_medhigh_usecase_count,\n",
    "  fms.azure_medhigh_total_monthly_dbu,\n",
    "  fms.threeplus_blocker_usecase_count,\n",
    "  fms.threeplus_blocker_total_monthly_dbu,\n",
    "  coalesce(u1.usecase_type, '') AS top1_usecase_type,\n",
    "  coalesce(u1.usecase_type_count, 0) AS top1_usecase_type_count,\n",
    "  coalesce(u1.usecase_type_monthly_dbu, 0) AS top1_usecase_type_monthly_dbu,\n",
    "  coalesce(u2.usecase_type, '') AS top2_usecase_type,\n",
    "  coalesce(u2.usecase_type_count, 0) AS top2_usecase_type_count,\n",
    "  coalesce(u2.usecase_type_monthly_dbu, 0) AS top2_usecase_type_monthly_dbu,\n",
    "  coalesce(u3.usecase_type, '') AS top3_usecase_type,\n",
    "  coalesce(u3.usecase_type_count, 0) AS top3_usecase_type_count,\n",
    "  coalesce(u3.usecase_type_monthly_dbu, 0) AS top3_usecase_type_monthly_dbu,\n",
    "  coalesce(sc1.slippage_category, '') AS top1_slippage_category,\n",
    "  coalesce(sc1.slip_usecase_count, 0) AS top1_slip_usecase_count,\n",
    "  coalesce(sc1desc.description, '') AS top1_slippage_category_description,\n",
    "  coalesce(sc2.slippage_category, '') AS top2_slippage_category,\n",
    "  coalesce(sc2.slip_usecase_count, 0) AS top2_slip_usecase_count,\n",
    "  coalesce(sc2desc.description, '') AS top2_slippage_category_description,\n",
    "  coalesce(sc3.slippage_category, '') AS top3_slippage_category,\n",
    "  coalesce(sc3.slip_usecase_count, 0) AS top3_slip_usecase_count,\n",
    "  coalesce(sc3desc.description, '') AS top3_slippage_category_description,\n",
    "  coalesce(ac1.accel_category, '') AS top1_accel_category,\n",
    "  coalesce(ac1.accel_usecase_count, 0) AS top1_accel_usecase_count,\n",
    "  coalesce(ac1desc.description, '') AS top1_accel_category_description,\n",
    "  coalesce(ac2.accel_category, '') AS top2_accel_category,\n",
    "  coalesce(ac2.accel_usecase_count, 0) AS top2_accel_usecase_count,\n",
    "  coalesce(ac2desc.description, '') AS top2_accel_category_description,\n",
    "  coalesce(ac3.accel_category, '') AS top3_accel_category,\n",
    "  coalesce(ac3.accel_usecase_count, 0) AS top3_accel_usecase_count,\n",
    "  coalesce(ac3desc.description, '') AS top3_accel_category_description,\n",
    "  coalesce(v1.vertical, '') AS top1_vertical,\n",
    "  coalesce(v1.vertical_usecase_count, 0) AS top1_vertical_usecase_count,\n",
    "  coalesce(v2.vertical, '') AS top2_vertical,\n",
    "  coalesce(v2.vertical_usecase_count, 0) AS top2_vertical_usecase_count,\n",
    "  coalesce(v3.vertical, '') AS top3_vertical,\n",
    "  coalesce(v3.vertical_usecase_count, 0) AS top3_vertical_usecase_count,\n",
    "  split(fms.field_manager, ' ')[0] AS name,\n",
    "  split(fms.field_manager, ' ')[size(split(fms.field_manager, ' '))-1] AS surname,\n",
    "  concat(\n",
    "    lower(split(fms.field_manager, ' ')[0]), \n",
    "    '.', \n",
    "    lower(split(fms.field_manager, ' ')[size(split(fms.field_manager, ' '))-1]), \n",
    "    '@databricks.com'\n",
    "  ) AS generated_email,\n",
    "  concat(\n",
    "    lower(split(fms.field_manager, ' ')[0]), \n",
    "    '.', \n",
    "    lower(split(fms.field_manager, ' ')[size(split(fms.field_manager, ' '))-1]), \n",
    "    '@databricks.com'\n",
    "  ) AS email,\n",
    "  'correct' AS email_status\n",
    "FROM field_manager_summary fms\n",
    "LEFT JOIN usecase_type_ranked u1\n",
    "  ON fms.field_manager = u1.field_manager AND u1.rn = 1\n",
    "LEFT JOIN usecase_type_ranked u2\n",
    "  ON fms.field_manager = u2.field_manager AND u2.rn = 2\n",
    "LEFT JOIN usecase_type_ranked u3\n",
    "  ON fms.field_manager = u3.field_manager AND u3.rn = 3\n",
    "LEFT JOIN slip_categories sc1\n",
    "  ON fms.field_manager = sc1.field_manager AND sc1.rn = 1\n",
    "LEFT JOIN slip_categories sc2\n",
    "  ON fms.field_manager = sc2.field_manager AND sc2.rn = 2\n",
    "LEFT JOIN slip_categories sc3\n",
    "  ON fms.field_manager = sc3.field_manager AND sc3.rn = 3\n",
    "LEFT JOIN IDENTIFIER(:catalog || '.' || :schema || '.slippage_categories') sc1desc\n",
    "  ON sc1.slippage_category = sc1desc.type\n",
    "LEFT JOIN IDENTIFIER(:catalog || '.' || :schema || '.slippage_categories') sc2desc\n",
    "  ON sc2.slippage_category = sc2desc.type\n",
    "LEFT JOIN IDENTIFIER(:catalog || '.' || :schema || '.slippage_categories') sc3desc\n",
    "  ON sc3.slippage_category = sc3desc.type\n",
    "LEFT JOIN accel_categories ac1\n",
    "  ON fms.field_manager = ac1.field_manager AND ac1.rn = 1\n",
    "LEFT JOIN accel_categories ac2\n",
    "  ON fms.field_manager = ac2.field_manager AND ac2.rn = 2\n",
    "LEFT JOIN accel_categories ac3\n",
    "  ON fms.field_manager = ac3.field_manager AND ac3.rn = 3\n",
    "LEFT JOIN IDENTIFIER(:catalog || '.' || :schema || '.acceleration_categories') ac1desc\n",
    "  ON ac1.accel_category = ac1desc.type\n",
    "LEFT JOIN IDENTIFIER(:catalog || '.' || :schema || '.acceleration_categories') ac2desc\n",
    "  ON ac2.accel_category = ac2desc.type\n",
    "LEFT JOIN IDENTIFIER(:catalog || '.' || :schema || '.acceleration_categories') ac3desc\n",
    "  ON ac3.accel_category = ac3desc.type\n",
    "LEFT JOIN vertical_categories v1\n",
    "  ON fms.field_manager = v1.field_manager AND v1.rn = 1\n",
    "LEFT JOIN vertical_categories v2\n",
    "  ON fms.field_manager = v2.field_manager AND v2.rn = 2\n",
    "LEFT JOIN vertical_categories v3\n",
    "  ON fms.field_manager = v3.field_manager AND v3.rn = 3\n",
    "ORDER BY fms.field_manager;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Create sales manager summary view for executive reporting\n",
    "-- Aggregates use case metrics, confidence distribution, and top categories by sales manager\n",
    "CREATE OR REPLACE VIEW IDENTIFIER(:catalog || '.' || :schema || '.sales_manager_summary_view') (\n",
    "  snapshot_date,\n",
    "  sales_manager,\n",
    "  sales_region,\n",
    "  sales_subregion_level_1,\n",
    "  sales_subregion_level_2,\n",
    "  sales_subregion_level_3,\n",
    "  sales_subregion_level_4,\n",
    "  total_use_cases,\n",
    "  total_estimated_monthly_dbu,\n",
    "  high_confidence_count,\n",
    "  high_confidence_pct,\n",
    "  medium_confidence_count,\n",
    "  medium_confidence_pct,\n",
    "  low_confidence_count,\n",
    "  low_confidence_pct,\n",
    "  slip_usecase_count,\n",
    "  slip_total_monthly_dbu,\n",
    "  accel_usecase_count,\n",
    "  accel_total_monthly_dbu,\n",
    "  stale_usecase_count,\n",
    "  stale_total_monthly_dbu,\n",
    "  u3_stale_usecase_count,\n",
    "  u3_stale_total_monthly_dbu,\n",
    "  u5_stale_usecase_count,\n",
    "  u5_stale_total_monthly_dbu,\n",
    "  one_blocker_usecase_count,\n",
    "  one_blocker_total_monthly_dbu,\n",
    "  azure_medhigh_usecase_count,\n",
    "  azure_medhigh_total_monthly_dbu,\n",
    "  threeplus_blocker_usecase_count,\n",
    "  threeplus_blocker_total_monthly_dbu,\n",
    "  top1_usecase_type,\n",
    "  top1_usecase_type_count,\n",
    "  top1_usecase_type_monthly_dbu,\n",
    "  top2_usecase_type,\n",
    "  top2_usecase_type_count,\n",
    "  top2_usecase_type_monthly_dbu,\n",
    "  top3_usecase_type,\n",
    "  top3_usecase_type_count,\n",
    "  top3_usecase_type_monthly_dbu,\n",
    "  top1_slippage_category,\n",
    "  top1_slip_usecase_count,\n",
    "  top1_slippage_category_description,\n",
    "  top2_slippage_category,\n",
    "  top2_slip_usecase_count,\n",
    "  top2_slippage_category_description,\n",
    "  top3_slippage_category,\n",
    "  top3_slip_usecase_count,\n",
    "  top3_slippage_category_description,\n",
    "  top1_accel_category,\n",
    "  top1_accel_usecase_count,\n",
    "  top1_accel_category_description,\n",
    "  top2_accel_category,\n",
    "  top2_accel_usecase_count,\n",
    "  top2_accel_category_description,\n",
    "  top3_accel_category,\n",
    "  top3_accel_usecase_count,\n",
    "  top3_accel_category_description,\n",
    "  top1_vertical,\n",
    "  top1_vertical_usecase_count,\n",
    "  top2_vertical,\n",
    "  top2_vertical_usecase_count,\n",
    "  top3_vertical,\n",
    "  top3_vertical_usecase_count,\n",
    "  name,\n",
    "  surname,\n",
    "  generated_email,\n",
    "  email,\n",
    "  email_status\n",
    ") AS\n",
    "WITH sales_manager_summary AS (\n",
    "  SELECT\n",
    "    any_value(snapshot_date) as snapshot_date,\n",
    "    sales_manager,\n",
    "    any_value(sales_region) as sales_region,\n",
    "    any_value(sales_subregion_level_1) as sales_subregion_level_1,\n",
    "    any_value(sales_subregion_level_2) as sales_subregion_level_2,\n",
    "    any_value(sales_subregion_level_3) as sales_subregion_level_3,\n",
    "    any_value(sales_subregion_level_4) as sales_subregion_level_4,\n",
    "    COUNT(*) AS total_use_cases,\n",
    "    SUM(estimated_monthly_dollar_dbus) AS total_estimated_monthly_dbu,\n",
    "    SUM(CASE WHEN confidence_level_normalized = 'High' THEN 1 ELSE 0 END) AS high_confidence_count,\n",
    "    ROUND(100.0 * SUM(CASE WHEN confidence_level_normalized = 'High' THEN 1 ELSE 0 END) / COUNT(*), 2) AS high_confidence_pct,\n",
    "    SUM(CASE WHEN confidence_level_normalized = 'Medium' THEN 1 ELSE 0 END) AS medium_confidence_count,\n",
    "    ROUND(100.0 * SUM(CASE WHEN confidence_level_normalized = 'Medium' THEN 1 ELSE 0 END) / COUNT(*), 2) AS medium_confidence_pct,\n",
    "    SUM(CASE WHEN confidence_level_normalized = 'Low' THEN 1 ELSE 0 END) AS low_confidence_count,\n",
    "    ROUND(100.0 * SUM(CASE WHEN confidence_level_normalized = 'Low' THEN 1 ELSE 0 END) / COUNT(*), 2) AS low_confidence_pct,\n",
    "    SUM(CASE WHEN likely_to_slip = TRUE THEN 1 ELSE 0 END) AS slip_usecase_count,\n",
    "    SUM(CASE WHEN likely_to_slip = TRUE THEN estimated_monthly_dollar_dbus ELSE 0 END) AS slip_total_monthly_dbu,\n",
    "    SUM(CASE WHEN can_be_accelerated = TRUE THEN 1 ELSE 0 END) AS accel_usecase_count,\n",
    "    SUM(CASE WHEN can_be_accelerated = TRUE THEN estimated_monthly_dollar_dbus ELSE 0 END) AS accel_total_monthly_dbu,\n",
    "    SUM(CASE WHEN stage IN ('U3', 'U5') AND last_modified_date < date_sub(current_date(), 14) THEN 1 ELSE 0 END) AS stale_usecase_count,\n",
    "    SUM(CASE WHEN stage IN ('U3', 'U5') AND last_modified_date < date_sub(current_date(), 14) THEN estimated_monthly_dollar_dbus ELSE 0 END) AS stale_total_monthly_dbu,\n",
    "    SUM(CASE WHEN stage = 'U3' AND last_modified_date < date_sub(current_date(), 14) THEN 1 ELSE 0 END) AS u3_stale_usecase_count,\n",
    "    SUM(CASE WHEN stage = 'U3' AND last_modified_date < date_sub(current_date(), 14) THEN estimated_monthly_dollar_dbus ELSE 0 END) AS u3_stale_total_monthly_dbu,\n",
    "    SUM(CASE WHEN stage = 'U5' AND last_modified_date < date_sub(current_date(), 14) THEN 1 ELSE 0 END) AS u5_stale_usecase_count,\n",
    "    SUM(CASE WHEN stage = 'U5' AND last_modified_date < date_sub(current_date(), 14) THEN estimated_monthly_dollar_dbus ELSE 0 END) AS u5_stale_total_monthly_dbu,\n",
    "    SUM(CASE WHEN num_of_blockers = 1 THEN 1 ELSE 0 END) AS one_blocker_usecase_count,\n",
    "    SUM(CASE WHEN num_of_blockers = 1 THEN estimated_monthly_dollar_dbus ELSE 0 END) AS one_blocker_total_monthly_dbu,\n",
    "    SUM(CASE WHEN stage IN ('U2', 'U4', 'U5') AND confidence_level_normalized IN ('Medium', 'High') AND lower(target_cloud) LIKE '%azure%' THEN 1 ELSE 0 END) AS azure_medhigh_usecase_count,\n",
    "    SUM(CASE WHEN stage IN ('U2', 'U4', 'U5') AND confidence_level_normalized IN ('Medium', 'High') AND lower(target_cloud) LIKE '%azure%' THEN estimated_monthly_dollar_dbus ELSE 0 END) AS azure_medhigh_total_monthly_dbu,\n",
    "    SUM(CASE WHEN num_of_blockers >= 3 THEN 1 ELSE 0 END) AS threeplus_blocker_usecase_count,\n",
    "    SUM(CASE WHEN num_of_blockers >= 3 THEN estimated_monthly_dollar_dbus ELSE 0 END) AS threeplus_blocker_total_monthly_dbu\n",
    "  FROM IDENTIFIER(:catalog || '.' || :schema || '.pipelineiq_view')\n",
    "  GROUP BY sales_manager\n",
    "),\n",
    "slip_categories AS (\n",
    "  SELECT\n",
    "    sales_manager,\n",
    "    sc.slippage_category,\n",
    "    COUNT(*) AS slip_usecase_count,\n",
    "    ROW_NUMBER() OVER (PARTITION BY sales_manager ORDER BY COUNT(*) DESC) AS rn\n",
    "  FROM IDENTIFIER(:catalog || '.' || :schema || '.pipelineiq_view') sc\n",
    "  WHERE likely_to_slip = TRUE\n",
    "  GROUP BY sales_manager, slippage_category\n",
    "),\n",
    "accel_categories AS (\n",
    "  SELECT\n",
    "    sales_manager,\n",
    "    ac.accel_category,\n",
    "    COUNT(*) AS accel_usecase_count,\n",
    "    ROW_NUMBER() OVER (PARTITION BY sales_manager ORDER BY COUNT(*) DESC) AS rn\n",
    "  FROM IDENTIFIER(:catalog || '.' || :schema || '.pipelineiq_view') ac\n",
    "  WHERE can_be_accelerated = TRUE\n",
    "  GROUP BY sales_manager, accel_category\n",
    "),\n",
    "usecase_type_ranked AS (\n",
    "  SELECT\n",
    "    sales_manager,\n",
    "    usecase_type,\n",
    "    COUNT(*) AS usecase_type_count,\n",
    "    SUM(estimated_monthly_dollar_dbus) AS usecase_type_monthly_dbu,\n",
    "    ROW_NUMBER() OVER (PARTITION BY sales_manager ORDER BY SUM(estimated_monthly_dollar_dbus) DESC) AS rn\n",
    "  FROM IDENTIFIER(:catalog || '.' || :schema || '.pipelineiq_view')\n",
    "  GROUP BY sales_manager, usecase_type\n",
    "),\n",
    "vertical_categories AS (\n",
    "  SELECT\n",
    "    sales_manager,\n",
    "    vertical,\n",
    "    COUNT(*) AS vertical_usecase_count,\n",
    "    ROW_NUMBER() OVER (PARTITION BY sales_manager ORDER BY COUNT(*) DESC) AS rn\n",
    "  FROM IDENTIFIER(:catalog || '.' || :schema || '.pipelineiq_view')\n",
    "  GROUP BY sales_manager, vertical\n",
    ")\n",
    "SELECT\n",
    "  sms.snapshot_date,\n",
    "  sms.sales_manager,\n",
    "  sms.sales_region,\n",
    "  sms.sales_subregion_level_1,\n",
    "  sms.sales_subregion_level_2,\n",
    "  sms.sales_subregion_level_3,\n",
    "  sms.sales_subregion_level_4,\n",
    "  sms.total_use_cases,\n",
    "  sms.total_estimated_monthly_dbu,\n",
    "  sms.high_confidence_count,\n",
    "  sms.high_confidence_pct,\n",
    "  sms.medium_confidence_count,\n",
    "  sms.medium_confidence_pct,\n",
    "  sms.low_confidence_count,\n",
    "  sms.low_confidence_pct,\n",
    "  sms.slip_usecase_count,\n",
    "  sms.slip_total_monthly_dbu,\n",
    "  sms.accel_usecase_count,\n",
    "  sms.accel_total_monthly_dbu,\n",
    "  sms.stale_usecase_count,\n",
    "  sms.stale_total_monthly_dbu,\n",
    "  sms.u3_stale_usecase_count,\n",
    "  sms.u3_stale_total_monthly_dbu,\n",
    "  sms.u5_stale_usecase_count,\n",
    "  sms.u5_stale_total_monthly_dbu,\n",
    "  sms.one_blocker_usecase_count,\n",
    "  sms.one_blocker_total_monthly_dbu,\n",
    "  sms.azure_medhigh_usecase_count,\n",
    "  sms.azure_medhigh_total_monthly_dbu,\n",
    "  sms.threeplus_blocker_usecase_count,\n",
    "  sms.threeplus_blocker_total_monthly_dbu,\n",
    "  coalesce(u1.usecase_type, '') AS top1_usecase_type,\n",
    "  coalesce(u1.usecase_type_count, 0) AS top1_usecase_type_count,\n",
    "  coalesce(u1.usecase_type_monthly_dbu, 0) AS top1_usecase_type_monthly_dbu,\n",
    "  coalesce(u2.usecase_type, '') AS top2_usecase_type,\n",
    "  coalesce(u2.usecase_type_count, 0) AS top2_usecase_type_count,\n",
    "  coalesce(u2.usecase_type_monthly_dbu, 0) AS top2_usecase_type_monthly_dbu,\n",
    "  coalesce(u3.usecase_type, '') AS top3_usecase_type,\n",
    "  coalesce(u3.usecase_type_count, 0) AS top3_usecase_type_count,\n",
    "  coalesce(u3.usecase_type_monthly_dbu, 0) AS top3_usecase_type_monthly_dbu,\n",
    "  coalesce(sc1.slippage_category, '') AS top1_slippage_category,\n",
    "  coalesce(sc1.slip_usecase_count, 0) AS top1_slip_usecase_count,\n",
    "  coalesce(sc1desc.description, '') AS top1_slippage_category_description,\n",
    "  coalesce(sc2.slippage_category, '') AS top2_slippage_category,\n",
    "  coalesce(sc2.slip_usecase_count, 0) AS top2_slip_usecase_count,\n",
    "  coalesce(sc2desc.description, '') AS top2_slippage_category_description,\n",
    "  coalesce(sc3.slippage_category, '') AS top3_slippage_category,\n",
    "  coalesce(sc3.slip_usecase_count, 0) AS top3_slip_usecase_count,\n",
    "  coalesce(sc3desc.description, '') AS top3_slippage_category_description,\n",
    "  coalesce(ac1.accel_category, '') AS top1_accel_category,\n",
    "  coalesce(ac1.accel_usecase_count, 0) AS top1_accel_usecase_count,\n",
    "  coalesce(ac1desc.description, '') AS top1_accel_category_description,\n",
    "  coalesce(ac2.accel_category, '') AS top2_accel_category,\n",
    "  coalesce(ac2.accel_usecase_count, 0) AS top2_accel_usecase_count,\n",
    "  coalesce(ac2desc.description, '') AS top2_accel_category_description,\n",
    "  coalesce(ac3.accel_category, '') AS top3_accel_category,\n",
    "  coalesce(ac3.accel_usecase_count, 0) AS top3_accel_usecase_count,\n",
    "  coalesce(ac3desc.description, '') AS top3_accel_category_description,\n",
    "  coalesce(v1.vertical, '') AS top1_vertical,\n",
    "  coalesce(v1.vertical_usecase_count, 0) AS top1_vertical_usecase_count,\n",
    "  coalesce(v2.vertical, '') AS top2_vertical,\n",
    "  coalesce(v2.vertical_usecase_count, 0) AS top2_vertical_usecase_count,\n",
    "  coalesce(v3.vertical, '') AS top3_vertical,\n",
    "  coalesce(v3.vertical_usecase_count, 0) AS top3_vertical_usecase_count,\n",
    "  split(sms.sales_manager, ' ')[0] AS name,\n",
    "  split(sms.sales_manager, ' ')[size(split(sms.sales_manager, ' '))-1] AS surname,\n",
    "  concat(\n",
    "    lower(split(sms.sales_manager, ' ')[0]), \n",
    "    '.', \n",
    "    lower(split(sms.sales_manager, ' ')[size(split(sms.sales_manager, ' '))-1]), \n",
    "    '@databricks.com'\n",
    "  ) AS generated_email,\n",
    "  concat(\n",
    "    lower(split(sms.sales_manager, ' ')[0]), \n",
    "    '.', \n",
    "    lower(split(sms.sales_manager, ' ')[size(split(sms.sales_manager, ' '))-1]), \n",
    "    '@databricks.com'\n",
    "  ) AS email,\n",
    "  'correct' AS email_status\n",
    "FROM sales_manager_summary sms\n",
    "LEFT JOIN usecase_type_ranked u1\n",
    "  ON sms.sales_manager = u1.sales_manager AND u1.rn = 1\n",
    "LEFT JOIN usecase_type_ranked u2\n",
    "  ON sms.sales_manager = u2.sales_manager AND u2.rn = 2\n",
    "LEFT JOIN usecase_type_ranked u3\n",
    "  ON sms.sales_manager = u3.sales_manager AND u3.rn = 3\n",
    "LEFT JOIN slip_categories sc1\n",
    "  ON sms.sales_manager = sc1.sales_manager AND sc1.rn = 1\n",
    "LEFT JOIN slip_categories sc2\n",
    "  ON sms.sales_manager = sc2.sales_manager AND sc2.rn = 2\n",
    "LEFT JOIN slip_categories sc3\n",
    "  ON sms.sales_manager = sc3.sales_manager AND sc3.rn = 3\n",
    "LEFT JOIN IDENTIFIER(:catalog || '.' || :schema || '.slippage_categories') sc1desc\n",
    "  ON sc1.slippage_category = sc1desc.type\n",
    "LEFT JOIN IDENTIFIER(:catalog || '.' || :schema || '.slippage_categories') sc2desc\n",
    "  ON sc2.slippage_category = sc2desc.type\n",
    "LEFT JOIN IDENTIFIER(:catalog || '.' || :schema || '.slippage_categories') sc3desc\n",
    "  ON sc3.slippage_category = sc3desc.type\n",
    "LEFT JOIN accel_categories ac1\n",
    "  ON sms.sales_manager = ac1.sales_manager AND ac1.rn = 1\n",
    "LEFT JOIN accel_categories ac2\n",
    "  ON sms.sales_manager = ac2.sales_manager AND ac2.rn = 2\n",
    "LEFT JOIN accel_categories ac3\n",
    "  ON sms.sales_manager = ac3.sales_manager AND ac3.rn = 3\n",
    "LEFT JOIN IDENTIFIER(:catalog || '.' || :schema || '.acceleration_categories') ac1desc\n",
    "  ON ac1.accel_category = ac1desc.type\n",
    "LEFT JOIN IDENTIFIER(:catalog || '.' || :schema || '.acceleration_categories') ac2desc\n",
    "  ON ac2.accel_category = ac2desc.type\n",
    "LEFT JOIN IDENTIFIER(:catalog || '.' || :schema || '.acceleration_categories') ac3desc\n",
    "  ON ac3.accel_category = ac3desc.type\n",
    "LEFT JOIN vertical_categories v1\n",
    "  ON sms.sales_manager = v1.sales_manager AND v1.rn = 1\n",
    "LEFT JOIN vertical_categories v2\n",
    "  ON sms.sales_manager = v2.sales_manager AND v2.rn = 2\n",
    "LEFT JOIN vertical_categories v3\n",
    "  ON sms.sales_manager = v3.sales_manager AND v3.rn = 3\n",
    "ORDER BY sms.sales_manager;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8afa7cfa-8c17-4b7b-ab09-a3c2535d8558",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Insert command for bootstrapping table from existing"
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# insert into users.sam_lecorre.pipelineiq \n",
    "#   SELECT \n",
    "#     -- Core identifiers and timestamps\n",
    "#     usecase_id,\n",
    "#     last_modified_date,\n",
    "#     CURRENT_DATE() - interval 1 day AS piq_last_updated,\n",
    "    \n",
    "#     -- Fields needed for AI inference (kept for reference)\n",
    "#     competition_string,\n",
    "    \n",
    "#     -- Number of blockers (used in reporting view)\n",
    "#     num_of_blockers,\n",
    "    \n",
    "#     -- AI enriched fields\n",
    "#     context,\n",
    "#     one_liner,\n",
    "#     next_steps_summary,\n",
    "#     implementation_notes_summary,\n",
    "#     blockers_summary,\n",
    "#     usecase_type,\n",
    "#     business_usecase_type,\n",
    "    \n",
    "#     -- Confidence scoring\n",
    "#     ai_confidence_score_advanced,\n",
    "#     confidence_score,\n",
    "#     confidence_level,\n",
    "#     rationale_for_confidence_score,\n",
    "#     pain_score,\n",
    "#     champion_score,\n",
    "#     implementationplan_score,\n",
    "#     decisionprocess_score,\n",
    "#     urgency_score,\n",
    "#     competitionawareness_score,\n",
    "#     majorblockers_score,\n",
    "#     measurableimpact_score,\n",
    "#     confidence_level_normalized,\n",
    "    \n",
    "#     -- Recommendations and classifications\n",
    "#     next_best_action_recommendation,\n",
    "#     likely_to_slip,\n",
    "#     slippage_category,\n",
    "#     can_be_accelerated,\n",
    "#     accel_category\n",
    "#   FROM users.luis_herrera.pipelineiq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "use catalog IDENTIFIER(:catalog);\n",
    "use schema IDENTIFIER(:schema);\n",
    "CREATE OR REPLACE TABLE slippage_categories\n",
    "USING DELTA\n",
    "AS SELECT * FROM VALUES\n",
    "  ('Technical', 'Slippage stems from missing features, technical blockers, or unresolved bugs'),\n",
    "  ('Business', 'Slippage is due to shifting business priorities, unclear value, or deprioritization'),\n",
    "  ('Stakeholder', 'Slippage results from lack of stakeholder buy-in, engagement, or sponsor turnover'),\n",
    "  ('Budget', 'Slippage is caused by funding gaps, delayed approvals, or budget freezes'),\n",
    "  ('Project Timelines', 'Slippage is driven by unrealistic schedules, missed milestones, or dependencies'),\n",
    "  ('Data', 'Slippage comes from data issues (access, quality, privacy, or integration)'),\n",
    "  ('Integration', 'Slippage is due to system connectivity, API, or tooling integration problems'),\n",
    "  ('Partner', 'Slippage originates from partner-side limitations, bandwidth, or enablement gaps'),\n",
    "  ('Hyperscaler', 'Slippage stems from hyperscaler constraints (region, quota, roadmap, or policies)'),\n",
    "  ('Competition', 'Slippage is triggered by market shifts or competitive reprioritization'),\n",
    "  ('External dependencies', 'Slippage comes from external third parties or customer-side dependencies'),\n",
    "  ('Other', 'Slippage cause unclear')\n",
    "AS t(type, description);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql \n",
    "use catalog IDENTIFIER(:catalog);\n",
    "use schema IDENTIFIER(:schema);\n",
    "CREATE OR REPLACE TABLE acceleration_categories \n",
    "USING DELTA\n",
    "AS SELECT * FROM VALUES\n",
    "  ('Implementation Planning', 'Acceleration comes from clarifying the WHAT/WHEN/WHO (critical path, milestones, owners)'),\n",
    "  ('Resource Allocation', 'The plan exists but we need people/tools/compute NOW'),\n",
    "  ('Stakeholder Engagement', 'Acceleration is through stakeholder alignment, exec cadence, or clearing decisions'),\n",
    "  ('Technical Optimization', 'Acceleration is via performance, architecture, or integration tuning'),\n",
    "  ('Innovation and Technology Enablement', 'Acceleration is via templates, automation, or accelerators (including AI assistants)'),\n",
    "  ('Governance and Support', 'Acceleration is via operating rhythm (steering, dashboards, SLAs, support processes)'),\n",
    "  ('Capability Development', 'Acceleration is via training/upskilling/knowledge transfer'),\n",
    "  ('Partnership Leverage', 'Acceleration comes when a partner''s expertise/assets are the key lever'),\n",
    "  ('Funding', 'Acceleration n is due to securing or expediting funding, budget approvals, or financial resources'),\n",
    "  ('Other', 'Unclear or does not fit any other acceleration motion')\n",
    "AS t(type, description);"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7687183143588512,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "incremental_pipeline",
   "widgets": {
    "catalog": {
     "currentValue": "users",
     "nuid": "e0056592-3829-4d1f-9413-22c944b6a70d",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "users",
      "label": "Target Catalog",
      "name": "catalog",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "users",
      "label": "Target Catalog",
      "name": "catalog",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "schema": {
     "currentValue": "sam_lecorre",
     "nuid": "720e5266-eb66-47b8-a510-9a9327dae3be",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "sam_lecorre",
      "label": "Target Schema",
      "name": "schema",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "sam_lecorre",
      "label": "Target Schema",
      "name": "schema",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
